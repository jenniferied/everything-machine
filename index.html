<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Artistic Research: Everything Machine (Kepler)</title>
    
    <!-- Externe CSS-Datei -->
    <link rel="stylesheet" href="style.css">
    
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- Google Font "IBM Plex Mono" -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@300;400;500&display=swap" rel="stylesheet">
</head>
<body class="antialiased">

    <!-- Header & Navigation (Nach Vorbild researchcatalogue.net) -->
    <header class="top-bar">
        <nav class="flex justify-between items-center w-full">
            <!-- Linke Seite: Navigation -->
            <div class="flex items-center">
                <!-- Dropdown -->
                <div class="relative">
                    <button id="contents-toggle" class="nav-link dropdown-toggle active" aria-haspopup="true">Inhalt</button>
                    <div id="dropdown-menu" class="dropdown-menu" role="menu">
                        <button class="dropdown-item active" data-page="overview" onclick="showPage('overview', this)" role="menuitem">Projektübersicht</button>
                        <button class="dropdown-item" data-page="logbook" onclick="showPage('logbook', this)" role="menuitem">Prozess-Logbuch</button>
                        <button class="dropdown-item" data-page="dialogues" onclick="showPage('dialogues', this)" role="menuitem">Künstler-Dialoge</button>
                    </div>
                </div>

                <!-- Mini-Player (Neu) -->
                <div class="mini-player-container hidden md:flex"> <!-- Player auf kleinen Screens ausblenden -->
                    <span class="nav-separator">|</span>
                    <button id="play-pause-button" class="play-pause-btn" aria-label="Play/Pause">
                        <!-- SVG Icons für Play/Pause (kleiner gemacht) -->
                        <svg class="icon-play" xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="currentColor" viewBox="0 0 16 16">
                            <path d="M11.596 8.697l-6.363 3.692c-.54.313-1.233-.066-1.233-.697V4.308c0-.63.692-1.01 1.233-.696l6.363 3.692a.802.802 0 0 1 0 1.393z"/>
                        </svg>
                        <svg class="icon-pause" xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="currentColor" viewBox="0 0 16 16">
                            <path d="M5.5 3.5A1.5 1.5 0 0 1 7 5v6a1.5 1.5 0 0 1-3 0V5A1.5 1.5 0 0 1 5.5 3.5zm5 0A1.5 1.5 0 0 1 12 5v6a1.5 1.5 0 0 1-3 0V5A1.5 1.5 0 0 1 10.5 3.5z"/>
                        </svg>
                    </button>
                    <div class="marquee-container">
                        <div class="marquee-content" id="marquee-content">
                            <!-- Content wird dynamisch von scripts.js generiert -->
                        </div>
                    </div>
                    <!-- Audio-Tag bleibt, wird von JS gesteuert -->
                    <audio id="audio-player" src="" preload="metadata"></audio>

                    <!-- Playlist Toggle Button (Neu) -->
                    <button id="playlist-toggle-btn" class="playlist-toggle-btn hidden md:flex" aria-label="Toggle Playlist">
                        <!-- SVG Icon für Playlist/Queue -->
                        <svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="currentColor" viewBox="0 0 16 16">
                            <path d="M12 13c0 1.105-1.12 2-2.5 2S7 14.105 7 13s1.12-2 2.5-2 2.5.895 2.5 2z"/>
                            <path d="M12 3c0 1.105-1.12 2-2.5 2S7 4.105 7 3s1.12-2 2.5-2 2.5.895 2.5 2z"/>
                            <path d="M0 3a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1H.5A.5.5 0 0 1 0 3zm0 10a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1H.5A.5.5 0 0 1 0 13zm0-5a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1H.5A.5.5 0 0 1 0 8z"/>
                        </svg>
                    </button>
                    <!-- Playlist Dropdown Container (Neu) -->
                    <div id="playlist-dropdown" class="playlist-dropdown">
                        <!-- Inhalt wird von JS generiert -->
                    </div>

                </div>
            </div>
            
            <!-- Rechte Seite: Titel -->
            <div class="text-right text-gray-400">
                <span>J. Meier - Everything Machine (Kepler) - 2025</span>
            </div>
        </nav>
    </header>

    <!-- Main Content Area (Lädt die "Seiten") -->
    <main class="container mx-auto">

        <!-- ===== SEITE 1: PROJEKTÜBERSICHT (Dein Exposé) ===== -->
        <section id="page-overview" class="page-content active">
            <div class="space-y-12 max-w-4xl mx-auto"> <!-- Zentriert für Lesbarkeit -->
                <!-- Abstract -->
                <div class="p-6 bg-gray-800 rounded-sm border border-gray-700">
                    <h3 class="text-lg font-bold mb-4 text-accent uppercase tracking-wider">I / O (Abstract)</h3>
                    <p class="text-lg italic">
                        Künstler verfügen über eine Fülle von "Inputs" – nicht nur Bilder, sondern auch Musik, Texte und einen schwer fassbaren "Vibe". Generative KI bietet neue "Output"-Werkzeuge, doch es fehlt an etablierten Prozessen, diese Inputs zur Erweiterung einer bestehenden digitalen Identität zu nutzen. Diese Arbeit untersucht dies in einem explorativen Artistic Research-Prozess am Fallbeispiel des Alter Egos "Kepler". In iterativen Zyklen und Künstler-Klienten-Dialogen wird ein Workflow entwickelt, der nicht nur neue Artefakte (Cover, Animationen) generiert, sondern auch dessen Auswirkung auf stilistische Kohärenz und künstlerische Autorschaft reflektiert.
                    </p>
                    <p class="mt-4 text-sm text-gray-500">Keywords: Generative AI, Multimodale Generierung, Artistic Research, Digitale Identität, Alter Ego, Cover Art, Animation</p>
                </div>

                <!-- Einleitung -->
                <div>
                    <h3 class="text-2xl font-bold mb-4 uppercase">Einleitung</h3>
                    <div class="prose prose-invert max-w-none text-gray-300 space-y-4">
                        <p>Die rasante Entwicklung generativer KI eröffnet neue Möglichkeiten in der künstlerischen Praxis. Für etablierte Künstler, die diese Werkzeuge in ihre bestehenden Workflows integrieren möchten, bedeutet dies eine Phase des Experimentierens, da etablierte "Best Practices" oft noch fehlen.</p>
                        <p>Dieses Artistic Research-Projekt knüpft an eine solche bestehende künstlerische Kollaboration an: die digitale Identität "Kepler" des Musikers Gavin Just. Aufbauend auf einer gemeinsamen Praxis, in der bereits digitale Album-/Song Cover und "Shorts" (Animationen) entstanden sind, stellt sich eine zentrale Herausforderung: Die visuelle Welt von Kepler entwickelt sich oft langsamer als die musikalische oder performative Ebene des Künstlers. Diese Diskrepanz steht in einem besonderen Spannungsfeld zu Keplers eigenem Narrativ – einer geplanten Transformation von einer 2D-Figur über eine 3D-Voxel-Gestalt bis hin zu einer realen und schließlich "hyperrealen" Existenz.</p>
                        
                        <!-- 
                        ACHTUNG: Aktualisiere diese Pfade, sodass sie auf deine Bilder im Ordner 'assets/images/' verweisen.
                        -->
                        <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
                            <img src="assets/images/kepler-voxel.png" alt="Kepler Voxel-Art" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/400x400/1f2937/9ca3af?text=Kepler+Voxel';this.onerror=null;">
                            <img src="assets/images/artefakt-1.png" alt="Projekt-Artefakt 1" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/400x400/1f2937/9ca3af?text=Artefakt+1';this.onerror=null;">
                            <img src="assets/images/artefakt-2.png" alt="Projekt-Artefakt 2" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/400x400/1f2937/9ca3af?text=Artefakt+2';this.onerror=null;">
                            <img src="assets/images/inspiration.png" alt="Inspiration-Board" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/400x400/1f2937/9ca3af?text=Inspiration';this.onerror=null;">
                        </div>

                        <p>Das Ziel dieser Arbeit ist es, einen explorativen, KI-gestützten Prozess zu entwickeln... Diese Herangehensweise ist von der Arbeit von Künstlern wie Refik Anadol inspiriert... In diesem Projekt wird der Einsatz von KI somit selbst zur Metapher für Keplers Transformation in eine "hyperreale" Identität.</p>
                    </div>
                </div>

                <!-- Forschungsfragen & Methodologie -->
                <div class="grid md:grid-cols-2 gap-8">
                    <div>
                        <h3 class="text-2xl font-bold mb-4 uppercase">Forschungsfragen</h3>
                        <ul class="list-disc list-inside space-y-3">
                            <li>Wie kann generative KI genutzt werden, um die stilistische Kohärenz einer bestehenden künstlerischen Identität zu wahren oder sinnvoll zu erweitern?</li>
                            <li>Inweit können bestehende Produktionsprobleme (z. B. die komplexe Animation von Voxel-Modellen) durch KI-Workflows gelöst oder kreativ umgangen werden?</li>
                            <li>Wie kann ein Workflow gestaltet werden, der die künstlerische Autorschaft wahrt und (urheber-)rechtliche Aspekte berücksichtigt?</li>
                            <li>Wie wird dieser explorative Prozess subjektiv vom "Künstler" (der Forschenden) und dem "Künstler-Klienten" (Gavin Just) wahrgenommen?</li>
                        </ul>
                    </div>
                    <div>
                        <h3 class="text-2xl font-bold mb-4 uppercase">Methodologie</h3>
                        <p class="mb-4">Diese Arbeit folgt keinem starren technischen Plan, sondern einer Methodik des explorativen Artistic Research. Der Prozess wird in drei iterative Zeitblöcke aufgeteilt...</p>
                        <p>Parallel wird ein reflexives Prozess-Tagebuch ("Logbuch") geführt. Jeder Block schließt mit einem semi-strukturierten "Künstler-Klienten-Dialog" mit Gavin Just...</p>
                        <!-- Platzhalter für das Zeitplan-Diagramm -->
                        <img src="assets/images/zeitplan.png" alt="Zeitplan" class="rounded-sm object-cover w-full h-auto mt-4" onerror="this.src='https://placehold.co/600x200/1f2937/9ca3af?text=Zeitplan-Diagramm+(Block+1-4)';this.onerror=null;">
                    </div>
                </div>

            </div>
        </section>

        <!-- ===== SEITE 2: PROZESS-LOGBUCH (Die fließenden Blöcke) ===== -->
        <section id="page-logbook" class="page-content">
            <h2 class="text-3xl font-bold mb-8 uppercase tracking-wider">Prozess-Logbuch</h2>
            <div class="logbook-grid">
                <!-- Log 1 -->
                <div class="logbook-item">
                    <span class="text-sm text-gray-400">Logbucheintrag 1 // 15. Nov 2025</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-accent">Block 1: Exploration & Setup</h3>
                    <p class="mb-4">Start des Projekts. Sammlung aller "Ground Truth"-Artefakte: Bestehende Cover (Unreal Engine), das Voxel-Modell und das geteilte Pinterest-Board. Erste Tests in ComfyUI, um ein Basis-Stilmodell (LoRA oder IPAdapter) mit diesen Inputs zu trainieren.</p>
                    <img src="assets/images/comfyui-graph.png" alt="ComfyUI Node Graph" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/600x400/111111/9ca3af?text=ComfyUI+Node+Graph';this.onerror=null;">
                </div>
                <!-- Log 2 -->
                <div class="logbook-item">
                    <span class="text-sm text-gray-400">Logbucheintrag 2 // 22. Nov 2025</span>
                    <h3 class="text-xl font-bold mt-2 mb-4">Input-Analyse: Der "Vibe"</h3>
                    <p class="mb-4">Analyse der non-visuellen Inputs. Ich habe mir das Album "BLUE EDITION" und die Single "Deine Moves" angehört und die Songtexte analysiert. Keywords: "Melancholie", "Digital", "Isolation", "Exoplanet". Diese Begriffe werden nun als Teil der Text-Prompts getestet, um zu sehen, wie sie den trainierten Stil beeinflussen.</p>
                </div>
                <!-- Log 3 -->
                <div class="logbook-item">
                    <span class="text-sm text-gray-400">Logbucheintrag 3 // 05. Dez 2025</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-accent">Block 2: Experiment A (Character Sheets)</h3>
                    <p class="mb-4">Versuch, konsistente Character Sheets zu erstellen. Das ist die größte Hürde. Ich nutze ControlNet (OpenPose) mit Posen aus den Fotoshoot-Bildern. Ergebnis: Die Posen sind konsistent, aber die Kleidung und Details (die Maske) variieren stark. Die "Identität" ist noch nicht stabil.</p>
                    <img src="assets/images/char-sheet-1.png" alt="Character Sheet Test 1" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/600x400/111111/9ca3af?text=Character+Sheet+Test+1';this.onerror=null;">
                </div>
                <!-- Log 4 -->
                <div class="logbook-item">
                    <span class="text-sm text-gray-400">Logbucheintrag 4 // 12. Dez 2025</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-accent">Block 2: Experiment B (Statische Welten)</h3>
                    <p class="mb-4">Parallel zu den Charakter-Tests: Generierung von "Statischen Welten" (Hintergründen) für Album Cover. Das funktioniert extrem gut. Die Kombination aus dem Stilmodell und den "Vibe"-Keywords erzeugt stimmige, melancholische Sci-Fi-Umgebungen. Diese könnte man leicht mit dem Voxel-Modell in After Effects kombinieren.</p>
                    <img src="assets/images/gen-cover.png" alt="Neues Cover (Gen BG)" class="rounded-sm object-cover w-full h-auto" onerror="this.src='https://placehold.co/600x600/111111/9ca3af?text=Neues+Cover+(Gen+BG)';this.onerror=null;">
                </div>
                <!-- Log 5 -->
                <div class="logbook-item">
                    <span class="text-sm text-gray-400">Logbucheintrag 5 // 10. Jan 2026</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-accent">Block 3: Experiment C (Animation)</h3>
                    <p class="mb-4">Beginn der Animationstests. Workflow 1: AnimateDiff auf die statischen Cover-Hintergründe (Log 4). Ergebnis: Gute, subtile Bewegungen (Wolken, Lichter). Ideal für Spotify Canvas.</p>
                    <p class="mb-4">Workflow 2: Versuch, eine animierte Sequenz mit einem ControlNet (Depth Map) aus Unreal Engine zu rendern. Ergebnis: Starke Fluktuation, Kohärenz bricht zusammen.</p>
                    <video controls muted class="rounded-sm w-full h-auto" poster="https://placehold.co/600x400/111111/9ca3af?text=Animation+Test+(AnimateDiff)">
                        <!-- Ersetze dies mit deinem Video-Pfad -->
                        <source src="assets/videos/anim-test.mp4" type="video/mp4">
                        Dein Browser unterstützt das Video-Tag nicht.
                    </video>
                </div>
                <!-- Log 6 -->
                <div class="logbook-item">
                    <span class="text-sm text-gray-400">Logbucheintrag 6 // 15. Jan 2026</span>
                    <h3 class="text-xl font-bold mt-2 mb-4">Reflexion: Urheberschaft & Ethik</h3>
                    <p class="mb-4">Während des Prozesses stellt sich die Ethik-Frage (Forschungsfrage 3). Unser Training basiert nur auf "eigenen Werken" (Gavins Musik, meine Artworks, unser Pinterest-Board). Wir nutzen keine Bilder von anderen Künstlern. Das fühlt sich "sauber" an. Die KI ist hier klar ein Werkzeug, das unseren Stil remixed, kein Ersatz für die Kreation.</p>
                </div>
                <!-- Log 7 / Evaluation -->
                <div class="logbook-item" style="grid-column: 1 / -1;"> <!-- Breiterer Block für Auswertung -->
                    <span class="text-sm text-gray-400">Logbucheintrag 7 // 01. Feb 2026</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-accent">Block 4: Evaluation & Reflexion</h3>
                    <p class="mb-4">Auswertung der Logbücher und Dialoge. Die Forschungsfragen können wie folgt beantwortet werden:
                       <br>1. **Kohärenz:** Die Kohärenz konnte für "Welten" und "Vibes" extrem gut gewahrt werden. Bei der "Charakter"-Generierung scheiterte sie.
                       <br>2. **Produktion:** Das Voxel-Problem wurde nicht *gelöst*, sondern *umgangen*. Der beste Workflow ist: **Voxel-Charakter (UE/C4D) + KI-Hintergrund (ComfyUI) + Compositing (AE)**.
                       <br>3. **Ethik:** Durch die Nutzung eines "sauberen" Input-Pools wurde die künstlerische Autorschaft gewahrt.
                       <br>4. **Reflexion:** Der Prozess wurde von beiden Parteien als extrem fruchtbar empfunden. Die KI dient als Inspirations- und Produktionspartner, nicht als Ersatz. Die Metapher der "hyperrealen" Transformation wurde bestätigt.
                    </p>
                </div>
            </div> <!-- Ende .logbook-grid -->
        </section>

        <!-- ===== SEITE 3: KÜNSTLER-DIALOGE (Gesonderte Seite) ===== -->
        <section id="page-dialogues" class="page-content">
            <h2 class="text-3xl font-bold mb-8 uppercase tracking-wider">Künstler-Klienten-Dialoge</h2>
            <div class="logbook-grid">
                <!-- Dialog 1 -->
                <div class="logbook-item dialog-item">
                    <span class="text-sm text-green-300">Dialog 1 (Audio-Transkript)</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-white">"Das fühlt sich schon nach Kepler an."</h3>
                    <p class="mb-4 italic">J.M: "Hier sind die ersten generierten Bilder, basierend auf unserem Pinterest-Board und den alten Covern. Erkennst du den Stil wieder?"</p>
                    <p class="mb-4 italic">G.J: "Ja, krass. Besonders Bild 3 und 5. Das ist genau die Farbstimmung. Die Voxel-Animation war immer so ein Krampf... wenn wir das umgehen könnten, wäre das mega. Lass uns versuchen, den Charakter damit konsistenter zu machen."</p>
                    <p class="text-sm text-green-300">Abschluss von Block 1. Nächster Schritt: Charakter-Kohärenz testen.</p>
                </div>

                <!-- Dialog 2 -->
                <div class="logbook-item dialog-item">
                    <span class="text-sm text-green-300">Dialog 2 (Zoom-Mitschrift)</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-white">"Der Hintergrund ja, der Charakter nein."</h3>
                    <p class="mb-4 italic">G.J: "Die Hintergründe (Log 4) sind perfekt. Das können wir sofort für das nächste Cover nutzen. Aber die generierten Charaktere (Log 3)... das ist nicht Kepler. Die Maske ist falsch. Das Voxel-Modell hat mehr Charakter."</p>
                    <p class="mb-4 italic">J.M: "Okay, das bestätigt meine Vermutung. Das Produktionsproblem der Voxel-Animation lösen wir so nicht direkt. Wir umgehen es, indem wir den Voxel-Charakter in die KI-Welten setzen."</p>
                    <p class="text-sm text-green-300">Abschluss von Block 2. Nächster Schritt: Animation (Dynamische Welten).</p>
                </div>

                <!-- Dialog 3 -->
                <div class="logbook-item dialog-item">
                    <span class="text-sm text-green-300">Dialog 3 (Finale)</span>
                    <h3 class="text-xl font-bold mt-2 mb-4 text-white">"Der beste Workflow: Hybrid"</h3>
                    <p class="mb-4 italic">J.M: "Nach allen Tests, was ist dein Fazit?"</p>
                    <p class="mb-4 italic">G.J: "Der Hybrid-Ansatz ist der Weg. Die KI ist eine 'Everything Machine' für die Welt, die Hintergründe, den Vibe (Log 5). Den Charakter selbst (das Voxel-Modell) behalten wir aber 'in-house', um die Kontrolle zu wahren. Die KI löst unser Voxel-Problem nicht, indem sie den Charakter ersetzt, sondern indem sie ihm eine Welt gibt, in der er existieren kann."</p>
                    <p class="text-sm text-green-300">Abschluss von Block 3. Nächster Schritt: Evaluation.</p>
                </div>
            </div> <!-- Ende .logbook-grid -->
        </section>

    </main>

    <footer class="text-center py-8 mt-12 border-t border-gray-800">
        <p class="text-sm text-gray-500">Ein Artistic Research-Projekt von Jennifer Meier (MA Medienproduktion).</p>
    </footer>

    <!-- Externe JavaScript-Datei -->
    <script src="scripts.js" defer></script>

</body>
</html>