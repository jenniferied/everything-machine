# KI wirklich verstehen

**11. Januar 2026**

Ich wollte Künstliche Intelligenz für mich selbst verstehen, auch außerhalb des Artistic Research-Kontexts, bevor ich dort weiter eintauchte. Nicht nur die Tools benutzen, die aufkommen, sondern verstehen, was gerade vor sich geht.

Eigentlich wollte ich auf der Autofahrt einen Podcast hören. Aber die meisten waren für einfache Anwendungsfälle: wie nutze ich ChatGPT, um E-Mails zu schreiben. Ich wollte tiefer rein. Ich hatte das Gefühl, dass manche Leute weiter sind als ich, und ich wollte genau die Lücken füllen.

Dann dachte ich: Perfekt wäre eigentlich KI selbst, weil die ja immer verfügbar ist. Also Freisprechanlage an, Claude im Chat-Interface, das meine Stimme in Text transkribierte. Zugegebenermaßen etwas gefährlich am Anfang – das System stockte manchmal, ich musste Sätze wiederholen, war abgelenkt. Aber dann hatten wir uns eingespielt, und es wurde zu einem echten Gespräch über 30 Minuten Fahrtzeit.

## Von der Mathematik zur KI

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich will mehr über KI lernen. Ich will das wirklich tiefer verstehen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Vielleicht kannst du ein Gespräch mit mir führen und mein Level einschätzen, und mir dann ein Level höher erklären?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Klar! Erzähl mir erstmal, was du schon weißt und womit du arbeitest.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Also ich nutze Claude Code gerade, hab ein paar GitHub-Repos für Research, schreibe meine Masterarbeit, mache generelle Recherche zu PhD-Themen...</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich hab Web-Development-Erfahrung und bin generell im Computer Graphics Bereich. Also breites aber vielleicht nicht super tiefes Wissen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich will die Grundlagen von KI und KI-Forschung verstehen. Wie fängt der Weg von der Mathematik zur KI an?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Gib mir ruhig lange Antworten. Ich kann gerade nicht lesen, also erkläre es ausführlich.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Mathematik ist die Sprache, die KI spricht, weil Computer nur Zahlen verstehen. Wenn ein Mensch ein Foto sieht, verarbeitet das Gehirn Farben, Formen und Muster sofort – aber ein Computer sieht dasselbe Foto als Millionen von Zahlen, die Pixelwerte darstellen. Jede KI beginnt damit, reale Informationen in mathematische Repräsentationen umzuwandeln, die Computer manipulieren können.</p>
    <p>Der Weg von einfacher Mathematik zu KI beginnt mit Statistik und Wahrscheinlichkeit. Wenn Menschen Entscheidungen treffen, berechnen sie unbewusst Chancen basierend auf vergangenen Erfahrungen. Wer dunkle Wolken sieht, greift wahrscheinlich zum Regenschirm, weil er gelernt hat, dass dunkle Wolken oft Regen bedeuten.</p>
    <p>Frühe KI-Forscher versuchten, genau das nachzuahmen: Systeme zu erschaffen, die aus Beispielen lernen, statt starren Regeln zu folgen. Statt einem Computer jeden möglichen Schachzug einzuprogrammieren, erkannten sie, dass man ihm Tausende von Schachpartien zeigen und ihn selbst Gewinnmuster entdecken lassen konnte.</p>
    <p>Dafür brauchte es drei mathematische Durchbrüche: Erstens lineare Algebra, um massive Datenmengen gleichzeitig zu verarbeiten. Zweitens Analysis, um die Schätzungen des Systems zu optimieren und zu verbessern. Drittens Wahrscheinlichkeitstheorie, um mit Unsicherheit umzugehen und Vorhersagen auch bei unvollständigen Informationen zu treffen.</p>
  </div>
</div>

## KI-Geschichte: Dartmouth 1956

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Hilf mir, den Weg von 1920 bis 2020 zu verstehen. Wann hat KI eigentlich angefangen? Wo wurde geforscht? Wie kam es zu Durchbrüchen?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Das formale Feld der künstlichen Intelligenz wurde auf der Dartmouth-Konferenz im Sommer 1956 geboren. Vier brillante Forscher überzeugten die Rockefeller Foundation, einen ambitionierten achtwöchigen Workshop zu finanzieren. Ihr Antrag war unglaublich kühn – sie glaubten, dass "jeder Aspekt des Lernens oder jede andere Eigenschaft der Intelligenz im Prinzip so präzise beschrieben werden kann, dass eine Maschine sie simulieren kann".</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ja, die Prägung des Begriffs. Erzähl mir mehr.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>John McCarthy von Dartmouth erfand buchstäblich den Begriff "Artificial Intelligence" für diesen Workshop, weil sie einen einprägsamen Namen für ihren Förderantrag brauchten. Vorher nannte man das "thinking machines" oder "electronic brains" – zu sehr nach Science-Fiction.</p>
    <p>Die ursprüngliche Gruppe umfasste McCarthy, der später die Programmiersprache LISP erfand; Marvin Minsky von Harvard, der zum Vater der KI am MIT wurde; Claude Shannon von Bell Labs, der die Informationstheorie erschuf und damit digitale Kommunikation erfand; und Nathaniel Rochester von IBM, der einige der ersten elektronischen Computer entwarf.</p>
    <p>Sie luden zehn Teilnehmer ein, darunter Allen Newell und Herbert Simon von Carnegie Mellon, die ihren "Logic Theorist" mitbrachten – ein Programm, das tatsächlich mathematische Theoreme beweisen konnte. Das war das erste echte KI-Programm, das funktionierte.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Oh, das ist super interessant. Das will ich in meiner Masterarbeit haben...</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Kannst du das noch mehr erklären? Das mit Claude Shannon?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Claude Shannons Informationstheorie von 1948 ist fundamental für alles in der KI. Shannon fand heraus, wie man Information mathematisch in Bits messen kann. Er bewies, dass jede Information – ob Text, Bilder oder Ton – in Binärcode umgewandelt und mit perfekter Genauigkeit übertragen werden kann, wenn genug Fehlerkorrektur hinzugefügt wird.</p>
    <p>Das ist gewaltig, weil es bedeutet, dass alles menschliche Wissen digitalisiert und von Maschinen verarbeitet werden kann. Shannons Arbeit bei Bell Labs ermöglicht direkt Computer, das Internet und jede digitale Technologie, die wir heute nutzen.</p>
    <p>Information hat eine mathematische Struktur. Ein Münzwurf liefert genau ein Bit Information, weil er Unsicherheit zwischen zwei gleich wahrscheinlichen Ergebnissen auflöst. Eine Nachricht, die sagt "die Sonne wird morgen aufgehen", enthält fast keine Information, weil sie nahezu sicher ist.</p>
    <p>Dieser mathematische Rahmen ermöglicht es Computern, Bedeutung zu verarbeiten – nicht nur Zahlen. Wenn jemand einen Satz tippt, reduziert jeder Buchstabe die Unsicherheit darüber, was als nächstes kommt, basierend auf Mustern in der Sprache. Moderne KI-Systeme nutzen dieses Prinzip, um das nächste Wort in einer Sequenz vorherzusagen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Okay. Super Erklärung. Kannst du da noch ein bisschen tiefer reingehen?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Und wird das heute noch benutzt, die symbolischen Repräsentationen? Das sind ja Weights und Biases jetzt, oder?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Symbolische KI und moderne neuronale Netze mit Gewichten und Bias sind fundamental unterschiedliche Ansätze zur Wissensrepräsentation.</p>
    <p>Der symbolische Ansatz versucht, Wissen explizit in menschenlesbaren Regeln und Logik zu erfassen. Wenn der Logic Theorist weiß "Alle Menschen sind sterblich", existiert diese Regel buchstäblich im Code als Symbole, die gelesen und verstanden werden können.</p>
    <p>Aber Gewichte und Bias in neuronalen Netzen repräsentieren Wissen auf eine völlig verteilte, implizite Weise. Ein neuronales Netz, das etwas über Sterblichkeit weiß, hat diese Regel nirgendwo geschrieben. Stattdessen entsteht dieses Wissen aus Millionen numerischer Gewichte, die statistische Muster über alle Trainingsdaten kodieren.</p>
    <p>Der Schlüsselunterschied: Symbolische KI speichert Wissen so, wie Menschen über Wissen denken – mit klaren Konzepten und logischen Beziehungen. Neuronale Netze speichern Wissen so, wie Gehirne tatsächlich funktionieren könnten – als Verbindungsstärken zwischen einfachen Verarbeitungseinheiten.</p>
  </div>
</div>

## Von Filtern zu GPT-2

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Large Language Models sind ja was anderes als Blur-Filter in Photoshop. Wir hatten ja schon Noise Reduction und Color Grading. Wieso fühlt sich jetzt alles gleichzeitig an?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Es gibt tatsächlich ein Spektrum von einfachen deterministischen Filtern bis zu moderner KI. Traditionelle Photoshop-Filter wenden feste mathematische Operationen an. Ein Blur-Filter konvolviert jedes Pixel mit seinen Nachbarn mit demselben Kernel. Deterministisch und vorhersagbar.</p>
    <p>Die erste Evolution waren adaptive Algorithmen. Noise Reduction in den frühen 2000ern begann, statistische Analyse zu nutzen, um Signal von Rauschen zu unterscheiden. Statt überall denselben Filter anzuwenden, analysierten diese Tools lokale Bildeigenschaften und passten ihr Verhalten an.</p>
    <p>Dann kam Machine Learning um 2010. Statt von Hand zu kodieren, wie man Kanten erkennt, trainierten Forscher Algorithmen auf Tausenden von gelabelten Beispielen. Das waren noch keine neuronalen Netze, sondern statistische Mustererkennung.</p>
    <p>Was alles veränderte, war Skalierung. GPUs machten es möglich, viel größere Netze auf viel mehr Daten zu trainieren. Dieselben mathematischen Prinzipien, die frühe Computer Vision antrieben, wurden plötzlich mächtig genug, um komplexe Muster in Bildern, Text und anderen Domänen zu erkennen.</p>
  </div>
</div>

## Transformer, RAG und Agents

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich nutze KI ja nicht nur für Text. Auch für Bilder, 3D, Video... MCP, Skills versus Agents. Können wir noch eine Sekunde auf dieser Ebene bleiben?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>GPT-2 war der Moment, in dem Forscher realisierten, dass Skalierung qualitativ neue Fähigkeiten erschafft – nicht nur bessere Leistung bei denselben Aufgaben.</p>
    <p>Vor GPT-2 dachte jeder, dass spezifische KI-Systeme für jede Aufgabe trainiert werden müssen. Will man Übersetzung? Trainiere ein Übersetzungsmodell. Will man Zusammenfassung? Trainiere ein Zusammenfassungsmodell. GPT-2 zeigte, dass ein genügend großes Sprachmodell, das einfach trainiert wurde, das nächste Wort vorherzusagen, plötzlich all diese Aufgaben erledigen konnte, ohne jemals explizit dafür trainiert worden zu sein.</p>
    <p>Das schockierte die Forscher. Sie erwarteten, dass größere Modelle besser darin werden, Text vorherzusagen, aber sie erwarteten nicht, dass sie spontan Reasoning-Fähigkeiten entwickeln würden, grundlegende Arithmetik oder die Fähigkeit, Code zu schreiben. Diese Fähigkeiten entstanden rein durch Skalierung.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Die zentrale Einsicht ist, dass Transformer – die Architektur, die Sprachmodelle antreibt – jeden Datentyp verarbeiten können, sobald er in Tokens umgewandelt ist. Text wird in Wort-Teile tokenisiert, Bilder werden in Patches unterteilt, Audio wird zu Spektrogrammen. Einmal alles in Tokens, kann dieselbe mathematische Maschinerie alles verarbeiten.</p>
    <p>Retrieval Augmented Generation (RAG), wie es Tools wie Claude Code nutzen, löst das Problem des Wissens-Cutoffs. Statt zu versuchen, alles während des Trainings zu memorieren, durchsuchen RAG-Systeme externe Datenbanken in Echtzeit und injizieren diese Information in den Kontext des Modells.</p>
    <p>MCP – Model Context Protocol – ist im Grunde ein standardisierter Weg für KI-Modelle, sich mit externen Tools und Datenquellen zu verbinden. Statt dass jede Firma eigene Integrationen baut, schafft MCP eine universelle Schnittstelle. Wie USB für KI.</p>
    <p>Skills sind spezifische Fähigkeiten, die eine KI ausführen kann – wie "Spreadsheets analysieren" oder "Code generieren". Sie sind reaktive Tools. Agents sind autonome Systeme, die planen, mehrere Schritte ausführen und selbstständig auf Ziele hinarbeiten können.</p>
    <p>Der vereinigende Faden sind Attention-Mechanismen – die mathematische Operation, die Transformern erlaubt, sich auf relevante Informationen zu fokussieren, unabhängig vom Datentyp. Deshalb explodieren KI-Fähigkeiten gleichzeitig über alle Domänen – dieselbe Kerntechnologie funktioniert überall, sobald das Tokenisierungsproblem gelöst ist.</p>
  </div>
</div>

## Wie lerne ich das wirklich?

Gegen Ende der Fahrt wurde mir klar: Ich hatte all das gehört, aber habe ich es wirklich gelernt?

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Okay, wenn ich dieses Thema wirklich tief verstehen will, und auch die Brücke schlagen will zu den Technologien, die ich benutze – Cursor, Claude Code für Research und Coding, ComfyUI, Houdini, Unreal Engine – was wäre der beste Weg dahin?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Sollte ich den Text selbst schreiben? Auch wenn du ihn generiert hast? Es gibt ja diese Studien, dass das Verständnis nicht so tief ist, wenn Essays mit KI geschrieben werden. Aber ich brauche dieses Fundament, um weiterzumachen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Andererseits habe ich das Gefühl, dass ich Wissen schrittweise aufbaue. Manchmal wollte ich Computer Graphics wirklich tief verstehen. Hab reingeschaut und dann aufgehört. Aber ich glaube, ich habe danach ein höheres Verständnis. Oder bilde ich mir das nur ein?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Zum Beispiel Houdini lernen – zum vierten oder fünften Mal. Ich mache langsam Fortschritte. Wie lernen menschliche Gehirne eigentlich?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich hatte meinen ersten Computer mit 7. Einfache Spiele, Kekse dekorieren. Dann hab ich viel gezeichnet und war im Internet, dann hab ich eine Pokemon-Website gemacht, indem ich HTML und CSS von jemand anderem kopiert habe. In der Schule hatte ich Programmieren, ganz basic. Dann Innenarchitektur studiert mit 3ds Max und am Ende Unreal Engine. Das ist viel. Ein langer Weg, um all dieses spezialisierte Wissen zu sammeln.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Du stellst die richtige Frage, und die ehrliche Antwort ist kompliziert.</p>
    <p>Die Forschung, die du meinst, ist real – wenn du etwas selbst schreibst, wirst du gezwungen, dich mit Lücken in deinem Verständnis auseinanderzusetzen. Lesen oder Zuhören fühlt sich wie Lernen an, weil die Information glatt fließt, aber diese Flüssigkeit ist trügerisch. Du kannst bei einer Erklärung von Backpropagation nicken, ohne sie fünf Minuten später selbst erklären zu können. Das nennt man die Fluency Illusion.</p>
    <p>Aber hier ist die Nuance: Es gibt verschiedene Arten von Wissen. Deklaratives Wissen ist "wissen dass" – Fakten, Konzepte, Geschichte. Prozedurales Wissen ist "wissen wie" – Dinge tatsächlich tun. Dein Weg von Kekse-Dekorieren über Pokemon-HTML zu 3ds Max zu Unreal ist prozedurales Wissen, das sich ansammelt. Das ist real und bleibt hängen auf eine Weise, die Lesen niemals erreicht.</p>
    <p>Dein Muster, Houdini aufzugreifen, fallen zu lassen, Monate später zurückzukommen und etwas besser zu sein – so funktioniert tiefes Lernen tatsächlich. Dein Gehirn konsolidiert während der Pausen. Schlaf, Zeit weg, angrenzende Dinge tun – das sind keine Misserfolge, das ist Teil des Prozesses. Der vierte Versuch fängt nicht von vorne an, er baut auf neuronalen Bahnen auf, die sich während der Versuche eins bis drei gebildet haben.</p>
    <p>Um KI-Verständnis mit deinen tatsächlichen Tools zu verbinden, würde ich vorschlagen: Schreib meinen Text nicht um. Stattdessen: Nimm einen Workflow, den du schon machst – vielleicht Depth-Map-Extraktion in ComfyUI – und verfolge die KI-Pipeline rückwärts. Welches Modell wird verwendet? Worauf wurde es trainiert? Was passiert mathematisch? Lernen, das an Tun geknüpft ist, bleibt hängen. Abstrakte Grundlagen ohne Anwendung schweben davon.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ja, ich fühle, dass es entscheidende Lücken gibt. Um es wirklich vollständig und tief zu verstehen.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Wo fühlst du die Lücken?</p>
    <p>Versuch mir zu erklären – der Akt des Artikulierens, wo dein Verständnis zusammenbricht, ist selbst diagnostisch. Kannst du zum Beispiel nachvollziehen, was passiert, wenn du einen Prompt in ComfyUI eingibst und ein Bild zurückbekommst? An welchem Punkt wird es zur Black Box?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Nur ganz leicht. Ich verstehe Bild- oder Video-Generierungsmodelle nicht ganz, und ich bin mir nicht sicher, wie interessiert ich daran bin.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich will eigentlich einen Lo-Fi Soviet Dystopian Winter Soundtrack mit KI erstellen. Vielleicht kann ich da anfangen.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Das ist ein großartiger Einstiegspunkt – spezifisch, kreativ, und persönlich interessant. Du wirst mehr lernen, wenn du dem nachjagst, als wenn du dich zwingst, Image Diffusion zu verstehen, das dich nicht interessiert.</p>
    <p>Was weißt du bisher über KI-Musikgenerierung? Hast du dir schon Tools angeschaut, oder ist das noch im Ideenstadium?</p>
  </div>
</div>

## Reflexion

- **Tools:** Claude App, Spracheingabe im Auto (30 Min.)
- **Workflow:** personalisierter Dialog statt Podcast/YouTube
- **Autorschaft:** die Fragende — Richtung und Tiefe bestimmt
- **Scheitern:** Spracheingabe-Bugs, Ablenkung durch Autofahrt
- **Erkenntnis:** Gefahr der Fluency Illusion — verstehen ≠ gehört haben

### Kontext

- **Tools:** Claude über die mobile App mit Spracheingabe, während einer 30-minütigen Autofahrt (Freisprechanlage)
- **Intention:** KI wirklich verstehen – nicht nur die Tools benutzen, sondern die mathematischen Grundlagen, Transformer, Diffusion Models und den Zusammenhang zu meinen Tools

### Die 5 Forschungsfragen

- **Workflow:** Komplett neuer Lernmodus – statt Podcast oder YouTube ein personalisiertes Gespräch. Die KI hat sich an mein Level angepasst, ich konnte jederzeit nachfragen. Dialog statt passives Konsumieren.
- **Autorschaft:** Die Fragende – ich habe die Richtung bestimmt, welche Themen, wie tief, welche Beispiele. Ohne meine Fragen wäre das Gespräch nirgendwohin gegangen.
- **Iteration:** Wissen gefestigt, an vergessene Konzepte erinnert – aber die Gefahr der Fluency Illusion bleibt.
- **Scheitern:** Nicht ganz flüssig (Bugs bei der Spracheingabe), von der Autofahrt abgelenkt, würde es so nicht wiederholen.
- **Ästhetik:** Würde öfter im Dialog mit KI lernen – das Format hat funktioniert.

### Synthese

- **Zentrale Erkenntnis:** Die Theorie ist jetzt da, irgendwo im Hinterkopf. Sie wird erst real, wenn ich sie anwende. Das Suno-Experiment war der direkte nächste Schritt – Claude hatte vorgeschlagen, KI-Verständnis an konkreten Projekten zu verankern.
- **Offene Frage:** Wie kann ich testen, ob ich wirklich verstanden habe – und nicht nur der Fluency Illusion unterliege?

**Keywords:** #FluencyIllusion #Transformer #KI-Geschichte #DialogischesLernen #Informationstheorie

<div class="interview-transcript">

<h4>Kontext</h4>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Welche Tools hast du verwendet?</p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Claude über die mobile App mit Spracheingabe, während einer 30-minütigen Autofahrt. Freisprechanlage an, quasi wie ein Telefonat.</p></div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Was wolltest du erreichen?</p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Ich wollte KI wirklich verstehen, nicht nur die Tools benutzen, sondern die Grundlagen. Was passiert mathematisch? Wie hängen Transformer, Diffusion Models und die Tools, die ich benutze, zusammen? Und wie lerne ich das am besten?</p></div>
</div>

<h4>Die 5 Forschungsfragen</h4>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Hat sich dein Arbeitsablauf verändert? <em>(Workflow)</em></p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Ein komplett neuer Lernmodus. Statt Podcast oder YouTube-Video hatte ich ein personalisiertes Gespräch. Die KI hat sich an mein Level angepasst, ich konnte jederzeit nachfragen. Dialog statt passives Konsumieren.</p></div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Wie hast du deine Rolle erlebt? <em>(Autorschaft)</em></p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Die Fragende. Ich habe die Richtung bestimmt, welche Themen, wie tief, welche Beispiele. Claude hat erklärt, aber ohne meine Fragen wäre das Gespräch nirgendwohin gegangen.</p></div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Wie hat die KI-Ausgabe deinen Prozess beeinflusst? <em>(Iteration)</em></p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Zum einen denke ich, dass ich mein bereits bekanntes Wissen noch einmal gestärkt habe und mich an ein paar Konzepte und historische Ereignisse erinnert habe, die ich schon vergessen hatte.</p>
  <p>Ich glaube aber, es könnte die Gefahr geben, dass ich der Illusion unterliege, dass ich es verstehe, obwohl ich es vielleicht nicht tue. Aber das Gleiche gilt ja auch, wenn ich mir ein Video anschaue.</p></div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Was ist schiefgelaufen? <em>(Scheitern)</em></p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Es lief noch nicht ganz so flüssig. Ich glaube, die Implementation von ChatGPT ist ein bisschen besser.</p>
  <p>Da wurde ich ein bisschen von der Autofahrt abgelenkt, ich würde das vielleicht nicht unbedingt noch einmal wiederholen. Wäre es jetzt wie ein Telefonat, dann ja, aber durch die Bugs lieber nicht. Aber sicherlich wird sich noch einiges tun in den nächsten Monaten.</p></div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Hat sich eine eigene 'Lern-Sprache' oder Methode entwickelt? <em>(Ästhetik)</em></p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Ich denke ich würde jetzt öfters im Dialog mit der KI versuchen Dinge zu lernen.</p></div>
</div>

<h4>Synthese</h4>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble"><p>Am Ende des Eintrags hast du geschrieben: 'Die Theorie wird erst real, wenn ich sie anwende. Nächster Schritt: Der Lo-Fi Soundtrack.' – Hast du das inzwischen gemacht?</p></div>
</div>
<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.png" alt="User"></div>
  <div class="chat-bubble"><p>Ja, das Suno-Experiment war der direkte nächste Schritt. Claude hatte vorgeschlagen, KI-Verständnis an konkreten Projekten zu verankern statt abstrakt zu lernen, und genau das habe ich dann gemacht.</p></div>
</div>

</div>
