# KI wirklich verstehen – Teil 1

**11. Januar 2026**

<div class="chat-intro">
Ich wollte Künstliche Intelligenz besser für mich selbst verstehen, auch außerhalb des Artistic Research Contexts, bevor ich dort weiter eintauchte. Ich wollte nicht nur die Tools benutzen, die aufkommen, sondern wirklich verstehen, was dort gerade vor sich geht.
</div>

<div class="chat-intro">
Eigentlich wollte ich auf der Autofahrt einen Podcast hören. Aber die meisten, die ich gefunden habe, waren für sehr einfache Anwendungsfälle – wie können normale Menschen ChatGPT nutzen, um E-Mails zu schreiben. Ich wollte in die tieferen Themen rein. Ich hatte das Gefühl, dass manche Leute viel weiter sind als ich, und ich wollte genau die Lücken aufholen, wo ich durchfalle.
</div>

<div class="chat-intro">
Dann dachte ich: Perfekt wäre eigentlich KI selbst, weil die ja immer verfügbar ist. Also Freisprechanlage an, Claude im Chat-Interface, das meine Stimme in Text transkribierte. Zugegebenermaßen etwas gefährlich am Anfang – das System stockte manchmal, ich musste Sätze wiederholen, war abgelenkt. Aber dann hatten wir uns eingespielt, und es wurde zu einem echten Gespräch über 30 Minuten Fahrtzeit.
</div>

---

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich will mehr über KI lernen. Ich will das wirklich tiefer verstehen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Vielleicht kannst du ein Gespräch mit mir führen und mein Level einschätzen, und mir dann ein Level höher erklären?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Klar! Erzähl mir erstmal, was du schon weißt und womit du arbeitest.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Also ich nutze Claude Code gerade, hab ein paar GitHub-Repos für Research, schreibe meine Masterarbeit, mache generelle Recherche zu PhD-Themen...</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich hab Web-Development-Erfahrung und bin generell im Computer Graphics Bereich. Also breites aber vielleicht nicht super tiefes Wissen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich will die Grundlagen von KI und KI-Forschung verstehen. Wie fängt der Weg von der Mathematik zur KI an?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Gib mir ruhig lange Antworten. Ich kann gerade nicht lesen, also erkläre es ausführlich.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Mathematik ist die Sprache, die KI spricht, weil Computer nur Zahlen verstehen. Wenn ein Mensch ein Foto sieht, verarbeitet das Gehirn Farben, Formen und Muster sofort – aber ein Computer sieht dasselbe Foto als Millionen von Zahlen, die Pixelwerte darstellen. Jede KI beginnt damit, reale Informationen in mathematische Repräsentationen umzuwandeln, die Computer manipulieren können.</p>
    <p>Der Weg von einfacher Mathematik zu KI beginnt mit Statistik und Wahrscheinlichkeit. Wenn Menschen Entscheidungen treffen, berechnen sie unbewusst Chancen basierend auf vergangenen Erfahrungen. Wer dunkle Wolken sieht, greift wahrscheinlich zum Regenschirm, weil er gelernt hat, dass dunkle Wolken oft Regen bedeuten.</p>
    <p>Frühe KI-Forscher versuchten, genau das nachzuahmen: Systeme zu erschaffen, die aus Beispielen lernen, statt starren Regeln zu folgen. Statt einem Computer jeden möglichen Schachzug einzuprogrammieren, erkannten sie, dass man ihm Tausende von Schachpartien zeigen und ihn selbst Gewinnmuster entdecken lassen konnte.</p>
    <p>Dafür brauchte es drei mathematische Durchbrüche: Erstens lineare Algebra, um massive Datenmengen gleichzeitig zu verarbeiten. Zweitens Analysis, um die Schätzungen des Systems zu optimieren und zu verbessern. Drittens Wahrscheinlichkeitstheorie, um mit Unsicherheit umzugehen und Vorhersagen auch bei unvollständigen Informationen zu treffen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ja. Das wurde ja im letzten Jahrhundert ein Ding... Das basiert auf Mathe.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Hilf mir, den Weg von 1920 bis 2020 zu verstehen. Wann hat KI eigentlich angefangen? Wo wurde geforscht? Wie kam es zu Durchbrüchen?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Das formale Feld der künstlichen Intelligenz wurde auf der Dartmouth-Konferenz im Sommer 1956 geboren. Vier brillante Forscher überzeugten die Rockefeller Foundation, einen ambitionierten achtwöchigen Workshop zu finanzieren. Ihr Antrag war unglaublich kühn – sie glaubten, dass "jeder Aspekt des Lernens oder jede andere Eigenschaft der Intelligenz im Prinzip so präzise beschrieben werden kann, dass eine Maschine sie simulieren kann".</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ja, die Prägung des Begriffs. Erzähl mir mehr.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>John McCarthy von Dartmouth erfand buchstäblich den Begriff "Artificial Intelligence" für diesen Workshop, weil sie einen einprägsamen Namen für ihren Förderantrag brauchten. Vorher nannte man das "thinking machines" oder "electronic brains" – zu sehr nach Science-Fiction.</p>
    <p>Die ursprüngliche Gruppe umfasste McCarthy, der später die Programmiersprache LISP erfand; Marvin Minsky von Harvard, der zum Vater der KI am MIT wurde; Claude Shannon von Bell Labs, der die Informationstheorie erschuf und damit digitale Kommunikation erfand; und Nathaniel Rochester von IBM, der einige der ersten elektronischen Computer entwarf.</p>
    <p>Sie luden zehn Teilnehmer ein, darunter Allen Newell und Herbert Simon von Carnegie Mellon, die ihren "Logic Theorist" mitbrachten – ein Programm, das tatsächlich mathematische Theoreme beweisen konnte. Das war das erste echte KI-Programm, das funktionierte.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Oh, das ist super interessant. Das will ich in meiner Masterarbeit haben...</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Kannst du das noch mehr erklären? Das mit Claude Shannon?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Claude Shannons Informationstheorie von 1948 ist fundamental für alles in der KI. Shannon fand heraus, wie man Information mathematisch in Bits messen kann. Er bewies, dass jede Information – ob Text, Bilder oder Ton – in Binärcode umgewandelt und mit perfekter Genauigkeit übertragen werden kann, wenn genug Fehlerkorrektur hinzugefügt wird.</p>
    <p>Das ist gewaltig, weil es bedeutet, dass alles menschliche Wissen digitalisiert und von Maschinen verarbeitet werden kann. Shannons Arbeit bei Bell Labs ermöglicht direkt Computer, das Internet und jede digitale Technologie, die wir heute nutzen.</p>
    <p>Information hat eine mathematische Struktur. Ein Münzwurf liefert genau ein Bit Information, weil er Unsicherheit zwischen zwei gleich wahrscheinlichen Ergebnissen auflöst. Eine Nachricht, die sagt "die Sonne wird morgen aufgehen", enthält fast keine Information, weil sie nahezu sicher ist.</p>
    <p>Dieser mathematische Rahmen ermöglicht es Computern, Bedeutung zu verarbeiten – nicht nur Zahlen. Wenn jemand einen Satz tippt, reduziert jeder Buchstabe die Unsicherheit darüber, was als nächstes kommt, basierend auf Mustern in der Sprache. Moderne KI-Systeme nutzen dieses Prinzip, um das nächste Wort in einer Sequenz vorherzusagen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Okay. Super Erklärung. Kannst du da noch ein bisschen tiefer reingehen?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Und wird das heute noch benutzt, die symbolischen Repräsentationen? Das sind ja Weights und Biases jetzt, oder?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Symbolische KI und moderne neuronale Netze mit Gewichten und Bias sind fundamental unterschiedliche Ansätze zur Wissensrepräsentation.</p>
    <p>Der symbolische Ansatz versucht, Wissen explizit in menschenlesbaren Regeln und Logik zu erfassen. Wenn der Logic Theorist weiß "Alle Menschen sind sterblich", existiert diese Regel buchstäblich im Code als Symbole, die gelesen und verstanden werden können.</p>
    <p>Aber Gewichte und Bias in neuronalen Netzen repräsentieren Wissen auf eine völlig verteilte, implizite Weise. Ein neuronales Netz, das etwas über Sterblichkeit weiß, hat diese Regel nirgendwo geschrieben. Stattdessen entsteht dieses Wissen aus Millionen numerischer Gewichte, die statistische Muster über alle Trainingsdaten kodieren.</p>
    <p>Der Schlüsselunterschied: Symbolische KI speichert Wissen so, wie Menschen über Wissen denken – mit klaren Konzepten und logischen Beziehungen. Neuronale Netze speichern Wissen so, wie Gehirne tatsächlich funktionieren könnten – als Verbindungsstärken zwischen einfachen Verarbeitungseinheiten.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Okay. Wie realistisch ist es für mich, das zu verstehen?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich glaub nicht, dass es so sehr vom Anwendungsfall abhängt... Ich meine, Large Language Models sind ja was anderes als, sagen wir, Blur-Filter in Photoshop, oder?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich meine, wir hatten ja schon Noise Reduction und Color Grading. Wieso fühlt sich jetzt alles gleichzeitig an?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Es gibt tatsächlich ein Spektrum von einfachen deterministischen Filtern bis zu moderner KI. Traditionelle Photoshop-Filter wenden feste mathematische Operationen an. Ein Blur-Filter konvolviert jedes Pixel mit seinen Nachbarn mit demselben Kernel. Deterministisch und vorhersagbar.</p>
    <p>Die erste Evolution waren adaptive Algorithmen. Noise Reduction in den frühen 2000ern begann, statistische Analyse zu nutzen, um Signal von Rauschen zu unterscheiden. Statt überall denselben Filter anzuwenden, analysierten diese Tools lokale Bildeigenschaften und passten ihr Verhalten an.</p>
    <p>Dann kam Machine Learning um 2010. Statt von Hand zu kodieren, wie man Kanten erkennt, trainierten Forscher Algorithmen auf Tausenden von gelabelten Beispielen. Das waren noch keine neuronalen Netze, sondern statistische Mustererkennung.</p>
    <p>Was alles veränderte, war Skalierung. GPUs machten es möglich, viel größere Netze auf viel mehr Daten zu trainieren. Dieselben mathematischen Prinzipien, die frühe Computer Vision antrieben, wurden plötzlich mächtig genug, um komplexe Muster in Bildern, Text und anderen Domänen zu erkennen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Und ja. Und dann, je nachdem... GPT-2 kam raus...</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>GPT-2 war der Moment, in dem Forscher realisierten, dass Skalierung qualitativ neue Fähigkeiten erschafft – nicht nur bessere Leistung bei denselben Aufgaben.</p>
    <p>Vor GPT-2 dachte jeder, dass spezifische KI-Systeme für jede Aufgabe trainiert werden müssen. Will man Übersetzung? Trainiere ein Übersetzungsmodell. Will man Zusammenfassung? Trainiere ein Zusammenfassungsmodell. GPT-2 zeigte, dass ein genügend großes Sprachmodell, das einfach trainiert wurde, das nächste Wort vorherzusagen, plötzlich all diese Aufgaben erledigen konnte, ohne jemals explizit dafür trainiert worden zu sein.</p>
    <p>Das schockierte die Forscher. Sie erwarteten, dass größere Modelle besser darin werden, Text vorherzusagen, aber sie erwarteten nicht, dass sie spontan Reasoning-Fähigkeiten entwickeln würden, grundlegende Arithmetik oder die Fähigkeit, Code zu schreiben. Diese Fähigkeiten entstanden rein durch Skalierung.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ja. Jetzt ist es ja nicht mehr nur das Training der Modelle...</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Also ich nutze KI ja nicht nur für Text. Auch für Bilder, 3D, Video...</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>MCP, und jetzt Skills versus Agents und so. Können wir noch eine Sekunde auf dieser Ebene bleiben?</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Die zentrale Einsicht ist, dass Transformer – die Architektur, die Sprachmodelle antreibt – jeden Datentyp verarbeiten können, sobald er in Tokens umgewandelt ist. Text wird in Wort-Teile tokenisiert, Bilder werden in Patches unterteilt, Audio wird zu Spektrogrammen. Einmal alles in Tokens, kann dieselbe mathematische Maschinerie alles verarbeiten.</p>
    <p>Retrieval Augmented Generation (RAG), wie es Tools wie Claude Code nutzen, löst das Problem des Wissens-Cutoffs. Statt zu versuchen, alles während des Trainings zu memorieren, durchsuchen RAG-Systeme externe Datenbanken in Echtzeit und injizieren diese Information in den Kontext des Modells.</p>
    <p>MCP – Model Context Protocol – ist im Grunde ein standardisierter Weg für KI-Modelle, sich mit externen Tools und Datenquellen zu verbinden. Statt dass jede Firma eigene Integrationen baut, schafft MCP eine universelle Schnittstelle. Wie USB für KI.</p>
    <p>Skills sind spezifische Fähigkeiten, die eine KI ausführen kann – wie "Spreadsheets analysieren" oder "Code generieren". Sie sind reaktive Tools. Agents sind autonome Systeme, die planen, mehrere Schritte ausführen und selbstständig auf Ziele hinarbeiten können.</p>
    <p>Der vereinigende Faden sind Attention-Mechanismen – die mathematische Operation, die Transformern erlaubt, sich auf relevante Informationen zu fokussieren, unabhängig vom Datentyp. Deshalb explodieren KI-Fähigkeiten gleichzeitig über alle Domänen – dieselbe Kerntechnologie funktioniert überall, sobald das Tokenisierungsproblem gelöst ist.</p>
  </div>
</div>

---

## Wie lerne ich das wirklich?

<div class="chat-intro">
Gegen Ende der Fahrt wurde mir klar: Ich hatte jetzt all diese Informationen gehört – aber habe ich sie wirklich gelernt?
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Okay, wenn ich dieses Thema wirklich tief verstehen will, und auch die Brücke schlagen will zu den Technologien, die ich benutze – Cursor, Claude Code für Research und Coding, ComfyUI, Houdini, Unreal Engine – was wäre der beste Weg dahin?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Sollte ich den Text selbst schreiben? Auch wenn du ihn generiert hast? Es gibt ja diese Studien, dass das Verständnis nicht so tief ist, wenn Essays mit KI geschrieben werden. Aber ich brauche dieses Fundament, um weiterzumachen.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Andererseits habe ich das Gefühl, dass ich Wissen schrittweise aufbaue. Manchmal wollte ich Computer Graphics wirklich tief verstehen. Hab reingeschaut und dann aufgehört. Aber ich glaube, ich habe danach ein höheres Verständnis. Oder bilde ich mir das nur ein?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Zum Beispiel Houdini lernen – zum vierten oder fünften Mal. Ich mache langsam Fortschritte. Wie lernen menschliche Gehirne eigentlich?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich hatte meinen ersten Computer mit 7. Einfache Spiele, Kekse dekorieren. Dann hab ich viel gezeichnet und war im Internet, dann hab ich eine Pokemon-Website gemacht, indem ich HTML und CSS von jemand anderem kopiert habe. In der Schule hatte ich Programmieren, ganz basic. Dann Innenarchitektur studiert mit 3ds Max und am Ende Unreal Engine. Das ist viel. Ein langer Weg, um all dieses spezialisierte Wissen zu sammeln.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Du stellst die richtige Frage, und die ehrliche Antwort ist kompliziert.</p>
    <p>Die Forschung, die du meinst, ist real – wenn du etwas selbst schreibst, wirst du gezwungen, dich mit Lücken in deinem Verständnis auseinanderzusetzen. Lesen oder Zuhören fühlt sich wie Lernen an, weil die Information glatt fließt, aber diese Flüssigkeit ist trügerisch. Du kannst bei einer Erklärung von Backpropagation nicken, ohne sie fünf Minuten später selbst erklären zu können. Das nennt man die Fluency Illusion.</p>
    <p>Aber hier ist die Nuance: Es gibt verschiedene Arten von Wissen. Deklaratives Wissen ist "wissen dass" – Fakten, Konzepte, Geschichte. Prozedurales Wissen ist "wissen wie" – Dinge tatsächlich tun. Dein Weg von Kekse-Dekorieren über Pokemon-HTML zu 3ds Max zu Unreal ist prozedurales Wissen, das sich ansammelt. Das ist real und bleibt hängen auf eine Weise, die Lesen niemals erreicht.</p>
    <p>Dein Muster, Houdini aufzugreifen, fallen zu lassen, Monate später zurückzukommen und etwas besser zu sein – so funktioniert tiefes Lernen tatsächlich. Dein Gehirn konsolidiert während der Pausen. Schlaf, Zeit weg, angrenzende Dinge tun – das sind keine Misserfolge, das ist Teil des Prozesses. Der vierte Versuch fängt nicht von vorne an, er baut auf neuronalen Bahnen auf, die sich während der Versuche eins bis drei gebildet haben.</p>
    <p>Um KI-Verständnis mit deinen tatsächlichen Tools zu verbinden, würde ich vorschlagen: Schreib meinen Text nicht um. Stattdessen: Nimm einen Workflow, den du schon machst – vielleicht Depth-Map-Extraktion in ComfyUI – und verfolge die KI-Pipeline rückwärts. Welches Modell wird verwendet? Worauf wurde es trainiert? Was passiert mathematisch? Lernen, das an Tun geknüpft ist, bleibt hängen. Abstrakte Grundlagen ohne Anwendung schweben davon.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ja, ich fühle, dass es entscheidende Lücken gibt. Um es wirklich vollständig und tief zu verstehen.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Wo fühlst du die Lücken?</p>
    <p>Versuch mir zu erklären – der Akt des Artikulierens, wo dein Verständnis zusammenbricht, ist selbst diagnostisch. Kannst du zum Beispiel nachvollziehen, was passiert, wenn du einen Prompt in ComfyUI eingibst und ein Bild zurückbekommst? An welchem Punkt wird es zur Black Box?</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Nur ganz leicht. Ich verstehe Bild- oder Video-Generierungsmodelle nicht ganz, und ich bin mir nicht sicher, wie interessiert ich daran bin.</p>
  </div>
</div>

<div class="chat-message user">
  <div class="chat-avatar"><img src="/assets/icons/user.svg" alt="User"></div>
  <div class="chat-bubble">
    <p>Ich will eigentlich einen Lo-Fi Soviet Dystopian Winter Soundtrack mit KI erstellen. Vielleicht kann ich da anfangen.</p>
  </div>
</div>

<div class="chat-message claude">
  <div class="chat-avatar"><img src="/assets/icons/claude.svg" alt="Claude"></div>
  <div class="chat-bubble">
    <p>Das ist ein großartiger Einstiegspunkt – spezifisch, kreativ, und persönlich interessant. Du wirst mehr lernen, wenn du dem nachjagst, als wenn du dich zwingst, Image Diffusion zu verstehen, das dich nicht interessiert.</p>
    <p>Was weißt du bisher über KI-Musikgenerierung? Hast du dir schon Tools angeschaut, oder ist das noch im Ideenstadium?</p>
  </div>
</div>

---

## Reflexion

<div class="chat-intro">
Ich bin zu Hause angekommen und fühle mich... auf der einen Seite neugierig und etwas gesicherter in meinem Wissen. Ich habe ja diese Nachfragen gestellt, nachdem ich mich schon mehrfach an verschiedenen Zeitpunkten in den letzten Monaten und Jahren immer mal wieder mit KI beschäftigt habe. Das Gespräch hat mein Wissen gefestigt.
</div>

<div class="chat-intro">
Aber gleichzeitig habe ich das Gefühl, dass es ein Riesenfeld ist. Ich will mehr Gespräche führen, um die Theorie zu vertiefen. Ich will mit anderen darüber reden – ich habe schon Freunde damit genervt und versucht, meinen Eltern ein bisschen mehr zu erklären. Ich will es wirklich lernen und verstehen, ohne jetzt Dinge ausrechnen zu müssen.
</div>

<div class="chat-intro">
Es gibt diese Studie von Bastani et al. (2024), die zeigt, dass Studierende, die mit KI-Unterstützung lernen, das Material weniger gut behalten. Die Information fließt durch dich hindurch, aber sie bleibt nicht hängen. Die Fluency Illusion – du hast das Gefühl, etwas verstanden zu haben, weil du es gehört hast, aber das ist trügerisch.
</div>

<div class="chat-intro">
Trotzdem: Durch diese Website und durch die Dialoge, die ich hier darstellen kann, merke ich, dass mir das eigentlich gefällt. Zum Beispiel habe ich mit KI zusammen diese Chat-Bubbles konfiguriert. Das ist noch viel lockerer als eine systematische Literaturrecherche. Mein Feed ist voller Videos zu dem Thema. Und eventuell will ich in Artistic Research tiefer einsteigen – in genau dieses Feld.
</div>

<div class="chat-intro">
Die Theorie ist jetzt da, irgendwo im Hinterkopf. Aber sie wird erst real, wenn ich sie anwende. Nächster Schritt: Der Lo-Fi Soundtrack. Kreativ anfangen, rückwärts arbeiten, die Theorie sacken lassen.
</div>
